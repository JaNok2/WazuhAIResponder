# ğŸ¤– Wazuh + Ollama AI Alert Escalation
This project combines [Wazuh](https://github.com/wazuh/wazuh-docker) and [Ollama](https://ollama.com) AI to automatically escalate alerts based on local LLM (Mistral 7B).


## ğŸ“Œ About the Project
- âœ… Based on [`wazuh-docker`](https://github.com/wazuh/wazuh-docker) GitHub repository (single-node setup).
- âœ… Custom `active-response` script using Ollama AI.
- âœ… Alerts analyzed and escalated automatically via a local language model.
- âœ… Integration visible via Wazuh Dashboard UI.


## ğŸ—‚ Project Structure
wazuh-ollama-ai-integration/
â”œâ”€â”€ ğŸ“‚ wazuh-docker
â”‚   â””â”€â”€ ğŸ“‚ single-node
â”‚       â”œ-- ğŸ“„ docker-compose.yml
â”‚       â”œ-- ğŸ“„ ossec.conf
â”‚       â”œ--ğŸ“‚ rules
â”‚       â”‚   â””â”€â”€ ğŸ“„ local_rules.xml
â”‚       â””-- ğŸ“‚ active-response
â”‚           â””â”€â”€ ğŸ“‚ bin
â”‚               â””â”€â”€ ğŸ“„ ai-escalate.py
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ .gitignore
â””â”€â”€ ğŸ“„ requirements.txt


## âš™ï¸ Requirements
- Docker + Docker Compose
- Python 3 inside the Wazuh container
- [Ollama](https://ollama.com) installed locally (running on port `11434`)
- Pulled model: `mistral:7b-instruct`
- Wazuh Docker setup (single-node)
